{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119add19-e89b-40c6-82f2-228a6941e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9daabd37-f592-4767-9c13-7e3b4ac84580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'distractor3', 'distractor1', 'distractor2', 'correct_answer', 'support'],\n",
       "        num_rows: 11679\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'distractor3', 'distractor1', 'distractor2', 'correct_answer', 'support'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'distractor3', 'distractor1', 'distractor2', 'correct_answer', 'support'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "sciq_dataset = load_dataset(\"allenai/sciq\")\n",
    "sciq_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd84a532-8f76-4873-865b-3aaeb2d86545",
   "metadata": {},
   "source": [
    "### Sequential Model Distractors Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2045ba1-997a-417c-979c-85a1dde9fc89",
   "metadata": {},
   "source": [
    "Load model from https://huggingface.co/rizkiduwinanto/final-bart-question-generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f54d14b-4a9d-4895-895f-b0576954ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qa = BartForConditionalGeneration.from_pretrained('rizkiduwinanto/final-bart-question-generation').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50964fcd-6cf7-432a-b0b8-cc644eab2d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"In the first law, an object will not change its motion unless a force acts on it. In the second law, the force on an object is equal to its mass times its acceleration. In the third law, when two objects interact, they apply forces to each other of equal magnitude and opposite direction.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b438c5-5b6f-4391-b0e5-68df33cbafc8",
   "metadata": {},
   "source": [
    "Code for inference of question generation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f13ce18-0c4d-4f27-a674-a1e0dc7db590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Question: In the first law, an object will not change its motion unless a force acts on it. in the second law, the force on an object is equal to its mass times what? Answer: its acceleration']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def qa_inference(context):\n",
    "    text = \"Support: {}\".format(context)\n",
    "    max_length = 600\n",
    "    tokenized_inputs = tokenizer.encode_plus(text, return_tensors=\"pt\", max_length=max_length, truncation=True, padding='max_length').to(device) \n",
    "\n",
    "    output = model_qa.generate(input_ids=tokenized_inputs[\"input_ids\"], max_length=1024)\n",
    "    \n",
    "    answer = tokenizer.batch_decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return answer\n",
    "\n",
    "question_answer = qa_inference(text)\n",
    "question_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699e585-add1-4441-80b0-36dcade05a12",
   "metadata": {},
   "source": [
    "Load model from https://huggingface.co/rizkiduwinanto/final-bart-distractor-generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c81b9a4-1b9b-454f-ace2-13642d28f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_da = BartForConditionalGeneration.from_pretrained('rizkiduwinanto/final-bart-distractor-generation').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847756a2-6b13-4e20-9b92-3db708cea11c",
   "metadata": {},
   "source": [
    "Code for inference of distractor generation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feb1fbdc-2346-4af0-86c9-d5246df488e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Distractor1: its velocity Distractor2: its weight Distractor3: its density']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def da_inference(context, result):\n",
    "    text = \"Support: {} {}\".format(context, result[0])\n",
    "    max_length = 600\n",
    "    tokenized_inputs = tokenizer.encode_plus(text, return_tensors=\"pt\", max_length=max_length, truncation=True, padding='max_length').to(device) \n",
    "\n",
    "    output = model_da.generate(input_ids=tokenized_inputs[\"input_ids\"], max_length=1024)\n",
    "    \n",
    "    answer = tokenizer.batch_decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return answer\n",
    "\n",
    "distractors = da_inference(text, question_answer)\n",
    "distractors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd54ed8-1d70-408f-95b7-bb6137e67c84",
   "metadata": {},
   "source": [
    "The pipeline for sequential generation, we do question answer inference first and then distractor generation. We extract the question answer and distractors from the labels e.g \"Distractors\" using Regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed116d9c-74f9-4739-bc75-1a2d6ad1c6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('In the first law, an object will not change its motion unless a force acts on it. in the second law, the force on an object is equal to its mass times what?',\n",
       " 'its acceleration',\n",
       " ['its velocity', 'its weight', 'its density'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def pipeline(context):\n",
    "    question_answer = qa_inference(context)\n",
    "    distractors = da_inference(context, question_answer)\n",
    "    \n",
    "    question_pattern = r\"Question: (.+?\\?)\"\n",
    "    answer_pattern = r\"Answer: (.+)\"\n",
    "    dis1_pattern = r\"Distractor1: (.+)\"\n",
    "    dis2_pattern = r\"Distractor2: (.+)\"\n",
    "    dis3_pattern = r\"Distractor3: (.+)\"\n",
    "\n",
    "    question = \"\"\n",
    "    answer = \"\"\n",
    "    \n",
    "    question_match = re.search(question_pattern, question_answer[0])\n",
    "    answer_match = re.search(answer_pattern, question_answer[0])\n",
    "\n",
    "    if question_match:\n",
    "        question = question_match.group(1)\n",
    "    if answer_match:\n",
    "        answer = answer_match.group(1)\n",
    "\n",
    "    distractor_pattern = r\"Distractor\\d+: (.+?)(?= Distractor|$)\"\n",
    "    distractors = re.findall(distractor_pattern, distractors[0])\n",
    "\n",
    "    return question, answer, distractors\n",
    "\n",
    "pipeline(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1e61e08-960e-4313-a054-055906c27058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'distractor3', 'distractor1', 'distractor2', 'correct_answer', 'support'],\n",
       "        num_rows: 10423\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'distractor3', 'distractor1', 'distractor2', 'correct_answer', 'support'],\n",
       "        num_rows: 881\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'distractor3', 'distractor1', 'distractor2', 'correct_answer', 'support'],\n",
       "        num_rows: 880\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sciq = sciq_dataset.filter(lambda example: example[\"support\"] != '')\n",
    "filtered_dataset = sciq_dataset.filter(lambda example: example['support'] is not None and example['support'] != \"\")\n",
    "# And remove any datapoints which contain questions that have a 'fill-in-the-blank' type answer\n",
    "filtered_sciq = filtered_dataset.filter(lambda example: '_______' not in example['question'] and '______' not in example['question'] and '_____' not in example['question'] and '____' not in example['question'] and '___' not in example['question'])\n",
    "filtered_sciq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6993958-7181-45c2-aeec-68303e1dea0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'distractor3', 'distractor1', 'distractor2', 'correct_answer', 'support'],\n",
       "    num_rows: 881\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = filtered_sciq['validation']\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e2a50e-d27b-45f8-9ef3-3343db4c7b38",
   "metadata": {},
   "source": [
    "Load the Word2Vec Model for distractor analysis. We use https://huggingface.co/fse/glove-wiki-gigaword-50 that encompasses the dictionary needed in science content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39d84b4c-cdf0-483a-b661-0a1ae11dc30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "glove_vectors = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88465719-34eb-4e80-8861-44d9352377f2",
   "metadata": {},
   "source": [
    "Testing the vectors from gensim library https://radimrehurek.com/gensim/models/word2vec.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1f94d97-605c-4981-bbba-20e4177c5142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('velocities', 0.8433403372764587),\n",
       " ('angle', 0.8210359215736389),\n",
       " ('angular', 0.8034953474998474),\n",
       " ('gravity', 0.7958716154098511),\n",
       " ('amplitude', 0.7937971353530884),\n",
       " ('wavelength', 0.7915680408477783),\n",
       " ('gradient', 0.7870423793792725),\n",
       " ('probability', 0.7667955756187439),\n",
       " ('frequency', 0.7655791640281677),\n",
       " ('measurement', 0.7501229047775269)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('velocity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd208aa7-70a0-4bb8-bdef-3e7ff7ca5810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22834066"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.similarity('angry', 'james')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "605792c4-6e3e-414c-9a53-4f1b3af05860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67458355"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.similarity('velocity', 'acceleration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "493c6a54-c6dd-4fd8-91f8-7c7c3196b94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5167572"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.similarity('weight', 'acceleration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67f650b7-cb72-482a-86b0-9786f4b1dc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5337082"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.similarity('density', 'acceleration')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d09d38-35b1-4fe8-9cb7-0ba035179d0f",
   "metadata": {},
   "source": [
    "We can see that very different words yields low score and nearly the same yields higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0c629e8-ec35-4195-b5f7-44619caea9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The smallest particle of an element that still has the properties of that element is called?',\n",
       " 'the atom',\n",
       " ['the electron', 'the neutron', 'the nucleus'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(test_data[469]['support'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504bd459-3844-4030-9910-bf4c04249c3b",
   "metadata": {},
   "source": [
    "Use map function to traverse the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1a83f16-ecfc-4b84-88c3-ea8ce9f9472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_all(examples):\n",
    "    question, answer, distractors = pipeline(examples['support'])\n",
    "    \n",
    "    return {\n",
    "        \"pred_answer\": answer if answer != None else \"\",\n",
    "        \"pred_question\": question,\n",
    "        \"pred_distractors1\": distractors[0] if len(distractors) > 0 else \"\",\n",
    "        \"pred_distractors2\": distractors[1] if len(distractors) > 1 else \"\",\n",
    "        \"pred_distractors3\": distractors[2] if len(distractors) > 2 else \"\",\n",
    "    }\n",
    "\n",
    "# test_data_sequential = test_data.map(infer_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35065df-0ae5-446e-a889-52b7fea6be85",
   "metadata": {},
   "source": [
    "To save inference time, data is already saved in the 'data.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d887cc6-c316-4a96-847f-ff09e812e8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "test_data_sequential = load_from_disk(\"data/res-sequential\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29b37ff3-2f9d-4881-a5dd-f74ffa171a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'The transfer of energy by electromagnetic waves is called what?',\n",
       " 'distractor3': 'magnetic radiation',\n",
       " 'distractor1': 'particulate radiation',\n",
       " 'distractor2': 'mechanical radiation',\n",
       " 'correct_answer': 'electromagnetic radiation',\n",
       " 'support': 'Electromagnetic waves are waves that consist of vibrating electric and magnetic fields. Like other waves, electromagnetic waves transfer energy from one place to another. The transfer of energy by electromagnetic waves is called electromagnetic radiation . Electromagnetic waves can transfer energy through matter or across empty space. For an excellent video introduction to electromagnetic waves, go to this URL: http://www. youtube. com/watch?v=cfXzwh3KadE.',\n",
       " 'pred_answer': 'magnetic fields',\n",
       " 'pred_question': 'Electromagnetic waves are waves that consist of vibrating electric and what else?',\n",
       " 'pred_distractors1': 'gravitational fields',\n",
       " 'pred_distractors2': 'electromagnetic currents',\n",
       " 'pred_distractors3': 'magnetic currents'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_sequential[170]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf52b08d-e753-4c27-9a0c-b500949eba8d",
   "metadata": {},
   "source": [
    "Use phrase vector function to average the word vector in two vectors, assume empty and not found as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26bdf35b-ec73-44e6-8106-c0a5b22d226e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def phrase_vector(phrase):\n",
    "    ## empty assume zero\n",
    "    if phrase == \"\":\n",
    "        wv = np.zeros(glove_vectors.vector_size)\n",
    "    else:\n",
    "        words = phrase.split()\n",
    "        word_vectors = [glove_vectors[word] for word in words if word in glove_vectors]\n",
    "        if len(word_vectors) == 0:\n",
    "            wv = np.zeros(glove_vectors.vector_size)\n",
    "        else:\n",
    "            wv = np.mean(word_vectors, axis=0)\n",
    "    return wv \n",
    "vec = phrase_vector(\"iron-def\")\n",
    "vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3026f986-6561-4552-bfee-b373c766ea74",
   "metadata": {},
   "source": [
    "Load the cosine similarity library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc0f7407-92ce-46ba-ac7d-7fa4524549fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68906325"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity([phrase_vector(\"happy\")], [phrase_vector(\"sad\")])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07672f08-5482-44ba-a193-671a82c0e64b",
   "metadata": {},
   "source": [
    "Function for ADS or answer distractor similarity that calculates the distance between each distractor to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17352d3d-9d4e-4b33-a83d-4bf32152630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vector_answer_dis(examples):\n",
    "    answer_vec = phrase_vector(examples['correct_answer'])\n",
    "    dis1_vec = phrase_vector(examples['distractor1'])\n",
    "    dis2_vec = phrase_vector(examples['distractor2'])\n",
    "    dis3_vec = phrase_vector(examples['distractor3'])\n",
    "\n",
    "    #distance between answers and distractors\n",
    "    sim_answer_dis1 = cosine_similarity([answer_vec], [dis1_vec])\n",
    "    sim_answer_dis2 = cosine_similarity([answer_vec], [dis2_vec])\n",
    "    sim_answer_dis3 = cosine_similarity([answer_vec], [dis3_vec])\n",
    "\n",
    "    sim_answer_dis = np.average([sim_answer_dis1, sim_answer_dis2, sim_answer_dis3])\n",
    "    return sim_answer_dis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef906cc7-9a5e-4d9f-b51e-a06ef9b50942",
   "metadata": {},
   "source": [
    "Function for IDS or answer distractor similarity that calculates the distance between each distractors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b205c0bf-f38d-4536-bffd-b6a059ca2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vector_inter_dis(examples):\n",
    "    dis1_vec = phrase_vector(examples['distractor1'])\n",
    "    dis2_vec = phrase_vector(examples['distractor2'])\n",
    "    dis3_vec = phrase_vector(examples['distractor3'])\n",
    "\n",
    "    #distance between each distractors\n",
    "    sim_dis1_dis2 = cosine_similarity([dis1_vec], [dis2_vec])\n",
    "    sim_dis2_dis3 = cosine_similarity([dis2_vec], [dis3_vec])\n",
    "    sim_dis3_dis1 = cosine_similarity([dis3_vec], [dis1_vec])\n",
    "\n",
    "    sim_dis = np.average([sim_dis1_dis2, sim_dis2_dis3, sim_dis3_dis1])\n",
    "    return sim_dis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052b9171-a477-4777-8493-1cb5c25dc880",
   "metadata": {},
   "source": [
    "ADS for prediction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96efba0b-f08e-4654-9e10-524f4c65802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vector_answer_dis_pred(examples):\n",
    "    answer_vec = phrase_vector(examples['pred_answer'])\n",
    "    dis1_vec = phrase_vector(examples['pred_distractors1'])\n",
    "    dis2_vec = phrase_vector(examples['pred_distractors2'])\n",
    "    dis3_vec = phrase_vector(examples['pred_distractors3'])\n",
    "\n",
    "     #distance between answers and distractors\n",
    "    sim_answer_dis1 = cosine_similarity([answer_vec], [dis1_vec])\n",
    "    sim_answer_dis2 = cosine_similarity([answer_vec], [dis2_vec])\n",
    "    sim_answer_dis3 = cosine_similarity([answer_vec], [dis3_vec])\n",
    "\n",
    "    sim_answer_dis = np.average([sim_answer_dis1, sim_answer_dis2, sim_answer_dis3])\n",
    "\n",
    "    return sim_answer_dis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026591f3-43e5-4bd1-9a7c-1d75d79bdf06",
   "metadata": {},
   "source": [
    "IDS for prediction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0894b47-f5d2-4649-80d0-9d4c17c8ee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vector_inter_dis_pred(examples):\n",
    "    dis1_vec = phrase_vector(examples['pred_distractors1'])\n",
    "    dis2_vec = phrase_vector(examples['pred_distractors2'])\n",
    "    dis3_vec = phrase_vector(examples['pred_distractors3'])\n",
    "\n",
    "    #distance between each distractors\n",
    "    sim_dis1_dis2 = cosine_similarity([dis1_vec], [dis2_vec])\n",
    "    sim_dis2_dis3 = cosine_similarity([dis2_vec], [dis3_vec])\n",
    "    sim_dis3_dis1 = cosine_similarity([dis3_vec], [dis1_vec])\n",
    "\n",
    "    sim_dis = np.average([sim_dis1_dis2, sim_dis2_dis3, sim_dis3_dis1])\n",
    "\n",
    "    return sim_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd95e184-7cbe-40c8-a6e8-3a5b39255519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distractor_analysis(test_data):\n",
    "    answer_dis = []\n",
    "    inter_dis = []\n",
    "    answer_pred_dis = []\n",
    "    inter_pred_dis = []\n",
    "    for data in test_data:\n",
    "        answer_dis.append(calc_vector_answer_dis(data))\n",
    "        inter_dis.append(calc_vector_inter_dis(data))\n",
    "        answer_pred_dis.append(calc_vector_answer_dis_pred(data))\n",
    "        inter_pred_dis.append(calc_vector_inter_dis_pred(data))\n",
    "\n",
    "    return answer_dis, inter_dis, answer_pred_dis, inter_pred_dis\n",
    "\n",
    "answer_dis_seq, inter_dis_seq, answer_pred_dis_seq, inter_pred_dis_seq = calc_distractor_analysis(test_data_sequential)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a42772d-f3ac-4b2e-a957-76b0a4fe94d5",
   "metadata": {},
   "source": [
    "Ground Truth Answer and Distractors Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba16edd5-c617-4035-8593-5a8c277a93e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5800197711281374"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(answer_dis_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54f550d-4133-40be-9eaf-0ec375bada6e",
   "metadata": {},
   "source": [
    "Ground Truth Inter Distractors Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e180970c-d5db-41c1-8b9e-b12bfdf3775d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5230395514299552"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(inter_dis_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67f5e14-cae1-43d4-9596-3004e88e2fa2",
   "metadata": {},
   "source": [
    "Predicted Answer and Distractors Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83d0259b-36a9-401d-842d-90e973561e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6643107100007571"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(answer_pred_dis_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abffe7cf-0121-4c08-b0ec-84543cd23e45",
   "metadata": {},
   "source": [
    "Predicted Inter Distractors Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edff2bda-20e1-480d-bd3f-32010ff39832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6502474400676812"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(inter_pred_dis_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d508b29-dcdc-4edf-bc98-8204124fbad6",
   "metadata": {},
   "source": [
    "The model produces more synonymous words than expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f3c90a-ecd5-4760-9846-d3b99a8fb40b",
   "metadata": {},
   "source": [
    "Sequential Model Question Analysis with BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63b7fd7a-0818-4bb2-b06d-081854d51466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0203, 0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def calc_bleu(test_data):\n",
    "    bleus1 = []\n",
    "    bleus2 = []\n",
    "    bleus3 = []\n",
    "    bleus4 = []\n",
    "    for data in test_data:\n",
    "        predicted = \"Question: {} Answer {}\".format(data['pred_question'], data['pred_answer']).split()\n",
    "        references = \"Question: {} Answer {}\".format(data['question'], data['correct_answer']).split()\n",
    "        final_score1 = sentence_bleu(references, predicted, weights=(1, 0, 0, 0))\n",
    "        final_score2 = sentence_bleu(references, predicted, weights=(0, 1, 0, 0))\n",
    "        final_score3 = sentence_bleu(references, predicted, weights=(0, 0, 1, 0))\n",
    "        final_score4 = sentence_bleu(references, predicted, weights=(0, 0, 0, 1))\n",
    "        bleus1.append(final_score1)\n",
    "        bleus2.append(final_score2)\n",
    "        bleus3.append(final_score3)\n",
    "        bleus4.append(final_score4)\n",
    "    \n",
    "    # Calculate the average BLEU score\n",
    "    average_bleu_score1 = np.mean(bleus1)\n",
    "    average_bleu_score2 = np.mean(bleus2)\n",
    "    average_bleu_score3 = np.mean(bleus3)\n",
    "    average_bleu_score4 = np.mean(bleus4)\n",
    "    \n",
    "    return round(average_bleu_score1, 4), round(average_bleu_score2, 4), round(average_bleu_score3, 4), round(average_bleu_score4, 4)\n",
    "\n",
    "calc_bleu(test_data_sequential)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c50446-d358-4945-ac8c-d7f7ea3eafb1",
   "metadata": {},
   "source": [
    "### Single Fine Tuned Model Distractors Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc94c2e-f8a2-4472-8821-1dd4d0aac065",
   "metadata": {},
   "source": [
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81394f08-2624-42cd-b929-fb37fad6fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_single_base = BartForConditionalGeneration.from_pretrained(\"b-b-brouwer/CL_base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92f025e8-32f6-4fda-9976-b9ce38d6b60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Question:Question: Which law states that an object will not change its motion unless a force acts on it? Answer: first law Distractor1:  third law and second law of inertia Distractor2: fourth law and third law of relativity Distractor3: law and law']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inference_sft(context, model):\n",
    "    text = \"Support: {}\".format(context)\n",
    "    max_length = 600\n",
    "    tokenized_inputs = tokenizer.encode_plus(text, return_tensors=\"pt\", max_length=max_length, truncation=True, padding='max_length').to(device) \n",
    "\n",
    "    output = model.generate(input_ids=tokenized_inputs[\"input_ids\"], max_length=1024)\n",
    "    \n",
    "    res = tokenizer.batch_decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return res\n",
    "    \n",
    "inference_sft(text, model_single_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cae2c8de-5c89-467a-870a-a8184d4f9bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_all_sft(examples, model):\n",
    "    result = inference_sft(examples['support'], model)\n",
    "\n",
    "    question_pattern = r\"Question: (.+?\\?)\"\n",
    "    answer_pattern = r\"Answer: (.+?)(?= Distractor\\d+: |$)\"\n",
    "    dis1_pattern = r\"Distractor1: (.+)\"\n",
    "    dis2_pattern = r\"Distractor2: (.+)\"\n",
    "    dis3_pattern = r\"Distractor3: (.+)\"\n",
    "\n",
    "    question = \"\"\n",
    "    answer = \"\"\n",
    "    \n",
    "    question_match = re.search(question_pattern, result[0])\n",
    "    answer_match = re.search(answer_pattern, result[0])\n",
    "\n",
    "    if question_match:\n",
    "        question = question_match.group(1)\n",
    "    if answer_match:\n",
    "        answer = answer_match.group(1)\n",
    "\n",
    "    distractor_pattern = r\"Distractor\\d+: (.+?)(?= Distractor|$)\"\n",
    "    distractors = re.findall(distractor_pattern, result[0])\n",
    "    \n",
    "    return {\n",
    "        \"pred_answer\": answer if answer != None else \"\",\n",
    "        \"pred_question\": question,\n",
    "        \"pred_distractors1\": distractors[0] if len(distractors) > 0 else \"\",\n",
    "        \"pred_distractors2\": distractors[1] if len(distractors) > 1 else \"\",\n",
    "        \"pred_distractors3\": distractors[2] if len(distractors) > 2 else \"\",\n",
    "    }\n",
    "\n",
    "# test_data_single_base = test_data.map(infer_all_sft, fn_kwargs={\"model\": model_single_base})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b2654-d7b6-4a48-a925-120ef0244e03",
   "metadata": {},
   "source": [
    "To save inference time, can use the data from data.zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42755d82-a111-4879-a612-924eb0889df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_single_base = load_from_disk(\"data/res-base-single\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c27e2-e67b-4818-a35b-da8164ccd144",
   "metadata": {},
   "source": [
    "Do a distractor analysis on single base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fe9cde3-b7b8-44ce-b872-92d8e80ef054",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_dis_sb, inter_dis_sb, answer_pred_dis_sb, inter_pred_dis_sb = calc_distractor_analysis(test_data_single_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84a71b23-9749-4dc5-87ec-8f6273393ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5800197711281374"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(answer_dis_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef8f5b14-6d18-4fa7-81c9-ea1a9b0b47a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5230395514299552"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(inter_dis_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aba40765-a769-40cf-9b20-92165576ec94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5562485193243836"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(answer_pred_dis_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ded280e-83f0-45fe-9b3c-bcd7009e91b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5263792485850741"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(inter_pred_dis_sb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f437b0a-9539-4f84-8992-bbbf8104a3bd",
   "metadata": {},
   "source": [
    "The model produces a comparable results to the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee116eb-89ff-418f-be20-01ca64b4492c",
   "metadata": {},
   "source": [
    "Do a BLEU analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "701e92cf-ed9e-4105-aa67-fd93e672a234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0187, 0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_bleu(test_data_single_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0018c402-f5ff-4986-a9d7-c6976505b59f",
   "metadata": {},
   "source": [
    "#### Large Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0b44995-c5e3-486d-98aa-f5023967fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_single_large = BartForConditionalGeneration.from_pretrained(\"b-b-brouwer/CL_large\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13c2c5ba-6b41-4bc2-80d8-246e968ef0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Question: In which law is the force on an object equal to its mass times its acceleration? Answer:  second law Distractor1:  third law of inertia Distractor2:  fourth law of gravity Distractor3:']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_sft(text, model_single_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "adca6c34-5872-4d28-8e3b-3fde8d3fd3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_single_large = test_data.map(infer_all_sft, fn_kwargs={\"model\": model_single_large})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc966792-7df8-405c-955d-1c2911636225",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_single_large = load_from_disk(\"data/res-large-single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b3f8e242-a9e7-4da0-b314-7229e3e601b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_dis_sl, inter_dis_sl, answer_pred_dis_sl, inter_pred_dis_sl = calc_distractor_analysis(test_data_single_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd52841-c818-4ef2-95c1-8db5fbf1ae77",
   "metadata": {},
   "source": [
    "Do a distractor analysis on single large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "37b98f68-91f4-48aa-accc-4d88c7f662bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5800197711281374"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(answer_dis_sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ef34fb3-b855-42d0-b718-73f96c044be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5230395514299552"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(inter_dis_sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8bc9a621-8cb0-47e4-ab53-e3e091dc9476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5562485193243836"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(answer_pred_dis_sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d688c19f-2b3c-4a59-b221-450c2a880c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5263792485850741"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(inter_pred_dis_sl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d77203-e5fb-41bf-a04d-5f61cc8f7a14",
   "metadata": {},
   "source": [
    "Do a BLEU analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f3be285c-e94f-4fee-b75a-5f0b48fd4fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0187, 0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_bleu(test_data_single_large)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
